{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have be using NLTK module of Python to extract keywords from reviews.csv file of AirBnB public dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from using pandas dataframe for reading and writing csv file, will carry basic Text Cleaning such as\n",
    "* Tokenization\n",
    "* Stopwords Removal\n",
    "* Lemmatization\n",
    "* POS tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have used POS tagging for keyword extraction. Generally adjectives are used for sentiment analysis, but here I have picked adjective and adverb from comments field of review, so that this application be easily extended for sentiment analysis  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It refers to the splitting of sentences and words from the body of text into sentence tokens or word tokens respectively. \n",
    "* It is an essential part of NLP, as many modules work better (or only) with tags. For example, pos_tag needs tags as input and not the words, to tag them by parts of speech.\n",
    "\n",
    "## Token\n",
    "\n",
    "Each \"entity\" that is a part of whatever was split up based on rules. For examples, each word is a token when a sentence is \"tokenized\" into words. Each sentence can also be a token, if you tokenized the sentences out of a paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Stop words are the words which are mostly used as fillers and hardly have any useful meaning. \n",
    "* We should avoid these words from taking up space in database or taking up valuable processing time. \n",
    "* We can easily make a list of words to be used as stop words and then filter these words from the data we want to process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Part of speech tagging creates tuples of words and parts of speech. \n",
    "* It labels words in a sentence as nouns, adjectives, verbs,etc. It can also label by tense, and more. \n",
    "* These tags mean whatever they meant in your original training data. \n",
    "* You are free to invent your own tags in your training data, as long as you are consistent in their usage.\n",
    "* Training data generally takes a lot of work to create, so a pre-existing corpus is typically used. \n",
    "    * These usually use the [Penn Treebank](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) and [Brown Corpus]((http://www.scs.leeds.ac.uk/ccalas/tagsets/brown.html) tags.\n",
    "    * Penn Treebank is probably the most common, but both corpora are available with NLTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Similar to stemming, where a word is replaced by its root\n",
    "+ The major difference that stemming can often create non-existent words, whereas lemmas are actual words, with same meaning. In that way, its more akin to sysnonym replacement.\n",
    "+ A lemma is a root word, as opposed to the root stem. \n",
    "+ Sometimes it may wind up with a completely different word.\n",
    "+ Lemmatize takes a part of speech parameter, \"pos.\" If not supplied, the default is \"noun.\"\n",
    "+ This means that an attempt will be made to find the closest noun, which can create trouble.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that you have unzipped the wordnet __corpus__ in \n",
    "\n",
    "    nltk_data/corpora/wordnet  \n",
    "    \n",
    "This will allow the __WordNetLemmatizer__ class to access WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The __WordNetLemmatizer__ class is a thin wrapper around the __wordnet corpus__ and uses the __morphy()__ function of the __WordNetCorpusReader__ class to find a lemma.\n",
    "* If no lemma is found, or the word itself is a lemma, the word is returned as is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "    os.getcwd()\n",
    "\n",
    "    os.setwd(\"path_to_directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"reviews_subset.csv\", sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['key_words'] = df['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "lemmatiser = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tokenizing text\n",
    "for t in range (0,len(df)) :\n",
    "    if pd.notnull(df.key_words[t]):\n",
    "        x = df.key_words[t]\n",
    "        words = word_tokenize(x)\n",
    "        words=[word.lower() for word in words if word.isalpha()]\n",
    "        filtered_sentence = []\n",
    "\n",
    "# Removing filler words        \n",
    "        for w in words:\n",
    "            if w not in stop_words:\n",
    "                filtered_sentence.append(w) \n",
    "\n",
    "# Lemmatizing filtered words                \n",
    "        custom_lemmas = []\n",
    "        for w in filtered_sentence:\n",
    "            word_tokens = word_tokenize(w)\n",
    "            for w in word_tokens:\n",
    "                custom_lemmas.append(lemmatiser.lemmatize(w))\n",
    "\n",
    "        tag = nltk.pos_tag(custom_lemmas)\n",
    "\n",
    "# Filtering keywords out of lemmas accoding to pos tagging        \n",
    "        keyword = []\n",
    "        count = 0\n",
    "\n",
    "        while count < len(tag):\n",
    "            if (tag[count][1] == \"JJ\" or tag[count][1] == \"RB\"):\n",
    "                keyword.append(tag[count][0])\n",
    "            count = count + 1\n",
    "\n",
    "        df.key_words[t] = ', '.join(keyword )\n",
    "df.to_csv(\"subset_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              comments  \\\n",
      "0    Very welcoming and pretty house, Kryshana and ...   \n",
      "1    Kryshana and Mike were excellent hosts. They a...   \n",
      "2    Exactamente lo que se ve en el anuncio todo en...   \n",
      "3    Kryshana and Michael  were very hospitable. Th...   \n",
      "4    Kryshana and Mike are very nice.. \\nthe apartm...   \n",
      "5    Kryshana is really nice and always answered ou...   \n",
      "6    We loved staying here.  Kryshana and Michael w...   \n",
      "7    Kryshana and Mike were very cool, friendly, ni...   \n",
      "8                Very accommodating and sweet couple.    \n",
      "9    Michael was welcoming - a good communication a...   \n",
      "10   Complessivamente il soggiorno è andato bene. K...   \n",
      "11   Kryshana and Mike were very accommodating host...   \n",
      "12   Amazing!! The emplacement is super convenient,...   \n",
      "13   Great spot! The apartment has everything you n...   \n",
      "14   Only issue was getting there initially, exact ...   \n",
      "15   Safe area and Conformable accommodations. Abou...   \n",
      "16   Overall I had a very positive experience. The ...   \n",
      "17   Great location. Very close to Columbia univers...   \n",
      "18   John’s apartment is clean and neat. Both bathr...   \n",
      "19   The host canceled this reservation the day bef...   \n",
      "20   Stayed at Johns place for a weekend with my fr...   \n",
      "21   John has been a fantastic host. He is super fr...   \n",
      "22   As advertised, clean and quiet, perfect for my...   \n",
      "23   I spent a few days with my daughter. John was ...   \n",
      "24                                 John 是个很好的人,和他聊天很愉快   \n",
      "25   John was a very kind host. Everythig was as wr...   \n",
      "26   nice and tidy room.  convenience for transport...   \n",
      "27   John was the perfect host with a clean, quiet,...   \n",
      "28   John's place is great. He allowed us to check-...   \n",
      "29   Very clean and comfortable. great food nearby,...   \n",
      "..                                                 ...   \n",
      "72   The place is in a great location. You can prac...   \n",
      "73   Yu is awesome, very helpful and will make sure...   \n",
      "74   Super clean, close to Penn station/subways, ea...   \n",
      "75   Yu was a fantastic host! I arrived last minute...   \n",
      "76   Yu was helpful in letting me drop off my bags ...   \n",
      "77   Yu is a very nice host, always ready to help. ...   \n",
      "78   I couldn't have asked for a better place to st...   \n",
      "79   It was so good. Yu was friendly and kind. Loca...   \n",
      "80   I had a good stay. Yu's place is very clean an...   \n",
      "81   Great location. Cool host. Place is clean as a...   \n",
      "82   Yu's place is very well located, clean and com...   \n",
      "83   Yu's place is in a perfect location, not even ...   \n",
      "84   Yu's place is fantastic. The location is centr...   \n",
      "85   It was the first time with Airbnb and Yu has b...   \n",
      "86   Yu was a helpful host, and respected the priva...   \n",
      "87   The room was clean, and the location was fanta...   \n",
      "88   Yu's apartment has a good location , if you ar...   \n",
      "89   This room was very small but my wife and I onl...   \n",
      "90   Yu was very nice and helpful, I didn't see him...   \n",
      "91   Appartement très propre et très bien localisé....   \n",
      "92   The location is impeccable, one block away fro...   \n",
      "93   Appartement très bien situé pour un premier sé...   \n",
      "94   Yu was a wonderful host. Apartment was clean a...   \n",
      "95   Good place, clean room and bathroom. you get g...   \n",
      "96                                             Great!    \n",
      "97   Yu was a nice host, he was really nice. He was...   \n",
      "98   Yu was very nice. He communicated with me the ...   \n",
      "99   Convenient and clean. Check-in and check-out w...   \n",
      "100  Yu was a very good host. The room and apartmen...   \n",
      "101  Yu is a nice guy, who responds to your message...   \n",
      "\n",
      "                                             key_words  \n",
      "0                    pretty, boyfriend, helpful, great  \n",
      "1    excellent, friendly, helpful, u, welcome, u, e...  \n",
      "2                                      atención, pasan  \n",
      "3    hospitable, good, well, picturesque, sunlight,...  \n",
      "4                  apartment, clean, quiet, good, away  \n",
      "5                  really, nice, always, quickly, good  \n",
      "6    friendly, helpful, large, clean, comfortable, ...  \n",
      "7    mike, friendly, nice, close, easy, midtown, fl...  \n",
      "8                                                sweet  \n",
      "9             good, comfortable, want, harlem, central  \n",
      "10                                             non, un  \n",
      "11                      u, welcome, away, subway, also  \n",
      "12   amazing, super, convenient, dead, cheap, nice,...  \n",
      "13   great, super, easy, great, beautiful, close, c...  \n",
      "14   initially, exact, available, little, tricky, o...  \n",
      "15   safe, conformable, cheap, otherwise, light, pe...  \n",
      "16               overall, positive, flat, last, storey  \n",
      "17                  great, close, columbia, easy, safe  \n",
      "18   clean, peacefully, place, courteous, extremely...  \n",
      "19                                                      \n",
      "20   john, great, u, comfortable, cozy, clean, nice...  \n",
      "21   fantastic, friendly, helpful, really, john, to...  \n",
      "22                   advertised, clean, quiet, perfect  \n",
      "23   spent, helpful, cosy, clean, conveniently, str...  \n",
      "24                                                      \n",
      "25     also, quickly, subway, highly, reccommend, john  \n",
      "26                        nice, well, responsible, new  \n",
      "27                      clean, quiet, friendly, uptown  \n",
      "28   john, great, u, late, due, late, u, even, clos...  \n",
      "29                   clean, comfortable, great, nearby  \n",
      "..                                                 ...  \n",
      "72   great, practically, see, square, front, profes...  \n",
      "73   yu, awesome, helpful, sure, nyc, clean, happy,...  \n",
      "74           super, close, penn, easy, square, midtown  \n",
      "75   yu, fantastic, last, minute, nyc, quickly, abl...  \n",
      "76   yu, helpful, later, even, together, awake, lou...  \n",
      "77                 nice, always, ready, clean, exactly  \n",
      "78       yu, great, amazing, definitely, stay, yu, new  \n",
      "79                good, friendly, real, central, clean  \n",
      "80                              good, yu, place, clean  \n",
      "81                                   great, definitely  \n",
      "82                                            yu, well  \n",
      "83   yu, even, penn, need, really, nice, friendly, ...  \n",
      "84   yu, fantastic, central, nyc, close, away, grea...  \n",
      "85   first, airbnb, yu, good, clean, good, easy, go...  \n",
      "86                           yu, helpful, really, good  \n",
      "87   clean, fantastic, penn, easy, flexible, unavai...  \n",
      "88       yu, good, fancy, clean, close, midtown, short  \n",
      "89   small, add, close, see, chelsea, clean, apt, n...  \n",
      "90                                nice, helpful, great  \n",
      "91                                         et, central  \n",
      "92   impeccable, away, penn, clean, minimal, really...  \n",
      "93                             pour, un, new, ne, nous  \n",
      "94   yu, wonderful, clean, quiet, definitely, stay,...  \n",
      "95   good, clean, good, private, close, subway, lit...  \n",
      "96                                               great  \n",
      "97                   nice, really, nice, always, u, ok  \n",
      "98   nice, sure, arrival, first, good, easy, unfort...  \n",
      "99                                   convenient, clean  \n",
      "100  yu, good, clean, close, penn, easy, main, litt...  \n",
      "101  nice, quiet, also, bad, late, easy, nice, nice...  \n",
      "\n",
      "[102 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[[\"comments\",\"key_words\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py33]",
   "language": "python",
   "name": "conda-env-py33-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
